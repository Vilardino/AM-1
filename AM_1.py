# -*- coding: utf-8 -*-
"""AM-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18AnNUNPUlsIrJwzO0J51fLuhe-WhMzII
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.datasets import make_blobs
from sklearn.preprocessing import MinMaxScaler, StandardScaler

import sklearn.metrics
from sklearn.metrics import accuracy_score

from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV

from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn import svm

"""# Código

##Leitura e tabela
"""

dados = pd.read_csv("https://github.com/Vilardino/AM-1/blob/main/Obesidade.csv?raw=true")
scaler = MinMaxScaler() 
#dados = dados.drop(columns=['Weight']) #quando nao comentado é retirado o peso do dataset
X = scaler.fit_transform(dados.iloc[0:, :16].to_numpy()) #trocar para 15 ao remover a coluna
Y = dados.iloc[0:,16].values #trocar para 15 ao remover a coluna

#dados.DESCR #ignora q ta dando bo
dados.head()

"""##Separa treino"""

x_tr, x_te, y_tr, y_te = train_test_split(X, Y,
                                            test_size = 0.2,
                                            random_state=33,
                                            stratify=Y)

print(x_tr.shape)
print(x_te.shape)

"""##Arvore de decisão"""

dtc = DecisionTreeClassifier(random_state=33)
dtc.fit(x_tr, y_tr)

y_pred = dtc.predict(x_te)
accuracy_score(y_te, y_pred)

conf_mat = sklearn.metrics.confusion_matrix(y_te, y_pred)


df_cm = pd.DataFrame(conf_mat, columns = ['IW', 'NW','OT_1', 'OT_2', 'OT_3', 'OL_1', 'OL_2'],
                     index = ['IW', 'NW','OT_1', 'OT_2', 'OT_3', 'OL_1', 'OL_2'])

cmap = sns.light_palette("#0622af", as_cmap=True)
plt.figure()
sns.heatmap(df_cm, annot=True, cmap=cmap)

tr_acc = []
tr_std = []

for this_md in range(2,50):
    dtc = DecisionTreeClassifier(max_depth=this_md,random_state=33)
    dtc.fit(x_tr, y_tr)
    scores = cross_val_score(dtc, x_tr, y_tr, cv=10)
    tr_acc.append(scores.mean())
    tr_std.append(np.std(scores))

"""###Erros com base na profundidade"""

plt.errorbar(x=range(2,50), y=tr_acc, yerr=tr_std)

param_grid = {'criterion': ['entropy', 'gini'],
              'max_depth': range(2,30,2),
              'min_samples_leaf': range(2,10,2),
              'min_impurity_decrease': np.linspace(0,0.5,10)}
dtc = DecisionTreeClassifier()
gs = GridSearchCV(dtc, param_grid=param_grid)
gs.fit(x_tr, y_tr)

gs.best_estimator_

"""###Arvore de decisão com melhores hiperparemetros"""

dtc = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=12, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=2, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort='deprecated',
                       random_state=33, splitter='best')

dtc.fit(x_tr, y_tr)
y_pred_DTC = dtc.predict(x_te)
accuracy_score(y_te, y_pred_DTC)

conf_mat = sklearn.metrics.confusion_matrix(y_te, y_pred_DTC)


df_cm = pd.DataFrame(conf_mat, columns = ['IW', 'NW','OT_1', 'OT_2', 'OT_3', 'OL_1', 'OL_2'],
                     index = ['IW', 'NW','OT_1', 'OT_2', 'OT_3', 'OL_1', 'OL_2'])

cmap = sns.light_palette("#0622af", as_cmap=True)
plt.figure()
sns.heatmap(df_cm, annot=True, cmap=cmap)

"""##Vizinhos próximos

"""

param_grid = {'weights': ['uniform', 'distance'],
              'n_neighbors': range(1,15,2),
              'metric': ['euclidean', 'manhattan']}

knc = KNeighborsClassifier()
gs = GridSearchCV(knc, param_grid=param_grid)
gs.fit(x_tr, y_tr)

gs.best_estimator_

knc = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,
                     weights='uniform')

knc.fit(x_tr, y_tr)
y_pred_knc = knc.predict(x_te)
accuracy_score(y_te, y_pred_knc)

conf_mat = sklearn.metrics.confusion_matrix(y_te, y_pred_knc)

df_cm = pd.DataFrame(conf_mat, columns = ['IW', 'NW','OT_1', 'OT_2', 'OT_3', 'OL_1', 'OL_2'],
                     index = ['IW', 'NW','OT_1', 'OT_2', 'OT_3', 'OL_1', 'OL_2'])

cmap = sns.light_palette("#0622af", as_cmap=True)
plt.figure()
sns.heatmap(df_cm, annot=True, cmap=cmap)

"""###Vizinhos próximos com escalonamento"""

scaler = StandardScaler().fit(x_tr)
x_tr_scaled = scaler.transform(x_tr)

param_grid = {'weights': ['uniform', 'distance'],
              'n_neighbors': range(1,15,2),
              'metric': ['euclidean', 'manhattan']}

knc2 = KNeighborsClassifier()
gs = GridSearchCV(knc2, param_grid=param_grid)
gs.fit(x_tr_scaled, y_tr)

gs.best_estimator_

knc2 = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,
                     weights='distance')

knc2.fit(x_tr_scaled, y_tr)
y_pred_knc2 = knc2.predict(scaler.transform(x_te))
accuracy_score(y_te, y_pred_knc2)

conf_mat = sklearn.metrics.confusion_matrix(y_te, y_pred_knc2)

df_cm = pd.DataFrame(conf_mat, columns = ['IW', 'NW','OT_1', 'OT_2', 'OT_3', 'OL_1', 'OL_2'],
                     index = ['IW', 'NW','OT_1', 'OT_2', 'OT_3', 'OL_1', 'OL_2'])

cmap = sns.light_palette("#0622af", as_cmap=True)
plt.figure()
sns.heatmap(df_cm, annot=True, cmap=cmap)

"""##Máquina de vetores de suporte"""

clf = svm.SVC(C = 100, gamma = 1, kernel='linear', random_state=33)
clf.fit(x_tr, y_tr)
y_pred = clf.predict(x_te)
print(accuracy_score(y_te, y_pred))

conf_mat = sklearn.metrics.confusion_matrix(y_te, y_pred)

df_cm = pd.DataFrame(conf_mat, columns = ['IW', 'NW','OT_1', 'OT_2', 'OT_3', 'OL_1', 'OL_2'],
                     index = ['IW', 'NW','OT_1', 'OT_2', 'OT_3', 'OL_1', 'OL_2'])

cmap = sns.light_palette("#0622af", as_cmap=True)
plt.figure()
sns.heatmap(df_cm, annot=True, cmap=cmap)